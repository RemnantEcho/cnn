{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meant to be for Task 5\n",
    "#### Untested and high erroneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import zipfile as zp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_labels = 10\n",
    "\n",
    "# Assign Zip Files to variable\n",
    "zf = zp.ZipFile('fashion-mnist_train.zip')\n",
    "zf1 = zp.ZipFile('fashion-mnist_test.zip')\n",
    "\n",
    "# Load CSV files from Zip Files\n",
    "train_data = np.loadtxt(zf.open('fashion-mnist_train.csv'), delimiter=',')\n",
    "test_data = np.loadtxt(zf1.open('fashion-mnist_test.csv'), delimiter=',')\n",
    "\n",
    "# Display images from 1 to 10\n",
    "# for i in range(10):\n",
    "#     img = train_imgs[i].reshape((28,28))\n",
    "#     plt.imshow(img, cmap=\"Greys\")\n",
    "#     plt.show()\n",
    "\n",
    "# Map image data values into intervals [0.01, 0.99]\n",
    "fac = 0.99 / 255\n",
    "add_fac = 0.01\n",
    "train_imgs = np.asfarray(train_data[:, 1:]) * fac + add_fac\n",
    "test_imgs = np.asfarray(test_data[:, 1:]) *fac + add_fac\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])\n",
    "\n",
    "lr = np.arange(num_of_labels)\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (lr==train_labels).astype(np.float64)\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float64)\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99\n",
    "\n",
    "# Create Pickle file from previous data\n",
    "with open(os.path.join(\".\",\"pkl_fashionmnist.pkl\"), \"bw\") as fh:\n",
    "    data = (train_imgs, \n",
    "            test_imgs, \n",
    "            train_labels,\n",
    "            test_labels,\n",
    "            train_labels_one_hot,\n",
    "            test_labels_one_hot)\n",
    "    pickle.dump(data, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "\n",
    "# Softmax\n",
    "def softmax(x):\n",
    "    expo = np.exp(x)\n",
    "    expo_sum = np.sum(np.exp(x))\n",
    "    return expo / expo_sum\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self,\n",
    "                train_data,\n",
    "                train_labels,\n",
    "                test_data,\n",
    "                test_labels,\n",
    "                num_of_input_nodes,\n",
    "                num_of_hidden_nodes,\n",
    "                active_input_percentage = 0.70,\n",
    "                active_hidden_percentage = 0.70,):\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "        self.test_data = test_data\n",
    "        self.test_labels = test_labels\n",
    "        self.num_of_input_nodes = num_of_input_nodes\n",
    "        self.num_of_hidden_nodes = num_of_hidden_nodes\n",
    "        self.active_input_percentage = active_input_percentage\n",
    "        self.active_hidden_percentage = active_hidden_percentage\n",
    "        \n",
    "        self.use_momentum = True\n",
    "        \n",
    "        self.epoch_nums = 100\n",
    "        \n",
    "        # default parameters\n",
    "        # self.num_of_hidden_nodes = 256\n",
    "#         self.num_of_epochs = 200\n",
    "#         self.batch_size = 100\n",
    "#         self.learning_rate = 1\n",
    "#         self.momentum = 0.9\n",
    "        \n",
    "        self.w0 = np.random.randn(self.train_data.shape[1], self.num_of_hidden_nodes) / np.sqrt(self.train_data.shape[1])\n",
    "        self.w1 = np.random.randn(self.num_of_hidden_nodes, len(self.train_labels)) / np.sqrt(self.num_of_hidden_nodes)\n",
    "    \n",
    "        self.v0 = np.zeros(self.w0.shape)\n",
    "        self.v1 = np.zeros(self.w1.shape)\n",
    "        \n",
    "    def dropout_weight_matrices(self):\n",
    "        # restore wih array, if it had been used for dropout\n",
    "        self.wih_orig = self.wih.copy()\n",
    "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
    "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
    "        self.who_orig = self.who.copy()\n",
    "        \n",
    "        active_input_nodes = int(self.num_of_input_nodes * self.active_input_percentage)\n",
    "        active_input_indices = sorted(random.sample(range(0, self.num_of_input_nodes), \n",
    "                                      active_input_nodes))\n",
    "        active_hidden_nodes = int(self.num_of_hidden_nodes * self.active_hidden_percentage)\n",
    "        active_hidden_indices = sorted(random.sample(range(0, self.num_of_hidden_nodes), \n",
    "                                       active_hidden_nodes))\n",
    "        \n",
    "        self.wih = self.wih[:, active_input_indices][active_hidden_indices]       \n",
    "        self.who = self.who[:, active_hidden_indices]\n",
    "        \n",
    "        self.no_of_hidden_nodes = active_hidden_nodes\n",
    "        self.no_of_in_nodes = active_input_nodes\n",
    "        return active_input_indices, active_hidden_indices\n",
    "        \n",
    "    def train(self, epoch_nums, batch_size, learning_rate, momentum, use_dropout):\n",
    "        Loss_list = []\n",
    "        lr = learning_rate\n",
    "        self.epoch_nums = epoch_nums\n",
    "        self.use_dropout = use_dropout\n",
    "        \n",
    "        for epoch in range(self.epoch_nums):\n",
    "            if epoch > 0:\n",
    "                lr *= 0.99\n",
    "            loss_epoch = []\n",
    "            \n",
    "            new_data = self.train_data\n",
    "            new_labels = self.train_labels\n",
    "            \n",
    "            if self.use_dropout == True:\n",
    "                new_data, new_labels = dropout_weight_matrices()\n",
    "            \n",
    "            for imgs, labels in zip(new_data, new_labels):\n",
    "                \n",
    "                # Forward pass\n",
    "                input_vector = sigmoid(np.matmul(imgs, self.w0))\n",
    "                log = np.matmul(input_vector, self.w1)\n",
    "                \n",
    "                soft = softmax(input_vector)\n",
    "                soft = np.clip(soft, 1e-16, 1)\n",
    "                \n",
    "                loss = -np.log(soft[np.arange(0, soft.shape[0]), labels])\n",
    "                \n",
    "                # Backward pass\n",
    "                delta_log = soft\n",
    "                delta_log[np.arange(0, delta_log.shape[0]), labels] -= 1\n",
    "                delta_log /= delta_log.shape[0]\n",
    "                \n",
    "                delta_w1 = np.matmul(input_vector.T, delta_log)\n",
    "                delta_l1 = np.matmul(delta_log, self.w1.T)\n",
    "                delta_l1 *= sigmoid(input_vector) * 1 - sigmoid(input_vector)\n",
    "                delta_w0 = np.matmul(imgs.T, delta_l1)\n",
    "                \n",
    "                if not self.use_momentum:\n",
    "                    self.w0 -= lr * delta_w0\n",
    "                    self.w1 -= lr * delta_w1\n",
    "                else:\n",
    "                    self.v0 = momentum * self.v0 + (1 - momentum) * delta_w0\n",
    "                    self.v1 = momentum * self.v1 + (1 - momentum) * delta_w1\n",
    "                    self.w0 -= lr * self.v0\n",
    "                    self.w1 -= lr * self.v1\n",
    "                    \n",
    "                if len(loss_epoch) == 0:\n",
    "                    loss_epoch = loss\n",
    "                else:\n",
    "                    loss_epoch = np.concatenate([loss_epoch, loss], axis = 0)\n",
    "            \n",
    "            mean = np.mean(loss_epoch)\n",
    "            Loss_list.append(mean)\n",
    "            if(epoch + 1) % 5 == 0:\n",
    "                print('Epoch: ' + (epoch + 1) + ' Loss: ' + np.mean(loss_epoch))\n",
    "        \n",
    "        return Loss_list\n",
    "            \n",
    "    def test(self):\n",
    "        total_correct = 0.0\n",
    "        imgs_batch, labels_batch = get_batch(self.input_test, self.target_test, self.batch_size)\n",
    "        \n",
    "        for imgs, labels in zip(self.test_data, self.test_labels):\n",
    "            input_vector = self.sigmoid(np.matmul(imgs))\n",
    "                                        \n",
    "            if self.use_dropout == True:\n",
    "                log = log * self.active_input_percentage\n",
    "                                        \n",
    "            log = np.matmul(layer1, self.w1)\n",
    "            soft = softmax(log)\n",
    "            pred = np.argmax(soft, axis = 1)\n",
    "            print('pred: ', pred)\n",
    "            print('labels: ', labels)\n",
    "            correct = len(np.where(pred == labels)[0])\n",
    "            print(\"correct: \", correct)\n",
    "            total_correct += correct\n",
    "            print('Total correct: ', total_correct/self.input_test.shape[0])\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 33\u001b[0m\n\u001b[0;32m     24\u001b[0m use_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     26\u001b[0m NN \u001b[38;5;241m=\u001b[39m NeuralNetwork(train_imgs, \n\u001b[0;32m     27\u001b[0m                    train_labels, \n\u001b[0;32m     28\u001b[0m                    test_imgs, \n\u001b[0;32m     29\u001b[0m                    test_labels, \n\u001b[0;32m     30\u001b[0m                    num_of_hidden_nodes, \n\u001b[0;32m     31\u001b[0m                    num_of_input_nodes)\n\u001b[1;32m---> 33\u001b[0m Loss \u001b[38;5;241m=\u001b[39m \u001b[43mNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_dropout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(NN\u001b[38;5;241m.\u001b[39mnum_epochs), Loss)\n\u001b[0;32m     36\u001b[0m NN\u001b[38;5;241m.\u001b[39mtest()\n",
      "Cell \u001b[1;32mIn [5], line 95\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[1;34m(self, epoch_nums, batch_size, learning_rate, momentum, use_dropout)\u001b[0m\n\u001b[0;32m     92\u001b[0m soft \u001b[38;5;241m=\u001b[39m softmax(input_vector)\n\u001b[0;32m     93\u001b[0m soft \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(soft, \u001b[38;5;241m1e-16\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[43msoft\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     98\u001b[0m delta_log \u001b[38;5;241m=\u001b[39m soft\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "# Load data from Pickle file\n",
    "with open(os.path.join(\".\",\"pkl_fashionmnist.pkl\"), \"br\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "train_imgs = data[0]\n",
    "test_imgs = data[1]\n",
    "train_labels = data[2]\n",
    "test_labels = data[3]\n",
    "train_labels_one_hot = data[4]\n",
    "test_labels_one_hot = data[5]\n",
    "\n",
    "img_size = 28 # dimensions\n",
    "num_of_labels = 10 # 0, 1, 2, ... 9\n",
    "image_pixels = img_size * img_size\n",
    "\n",
    "# Run 100 times\n",
    "epochs = 100\n",
    "\n",
    "num_of_input_nodes = image_pixels\n",
    "num_of_hidden_nodes = 256\n",
    "\n",
    "batch_size = 100\n",
    "learning_rate = 1\n",
    "momentum = 0.9\n",
    "use_dropout = False\n",
    "\n",
    "NN = NeuralNetwork(train_imgs, \n",
    "                   train_labels, \n",
    "                   test_imgs, \n",
    "                   test_labels, \n",
    "                   num_of_hidden_nodes, \n",
    "                   num_of_input_nodes)\n",
    "\n",
    "Loss = NN.train(epochs, batch_size, learning_rate, momentum, use_dropout)\n",
    "plt.plot(np.arange(NN.num_epochs), Loss)\n",
    "\n",
    "NN.test()\n",
    "\n",
    "\n",
    "# learning_rate = 0.5\n",
    "# Loss = NN.train(epochs, batch_size, learning_rate, momentum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
